{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOycagfOMHDNbGgZQK+NPcQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GreenOrange44/AIR/blob/main/HandsOn/HyperParametricTesting/HyperParametricTesting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We explore hyper para metric testing. The first model we will perfom with linear kernel of SVM, in that there is no parameters to finetune. SO after that we perform the same experiment with kerenl of SVM.\n",
        "\n",
        "Here we will perform HyperParametric testing with a grid approach, where the c and gamma value's grid will be formed and for each combination(the cartesian product of it) of them will be used to test the performance and the best parameter will be chosen"
      ],
      "metadata": {
        "id": "DNIs_UkLa58B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
        "\n",
        "\n",
        "# Assign column names to the dataset\n",
        "colnames = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'Class']\n",
        "\n",
        "# Read dataset to pandas dataframe\n",
        "irisdata = pd.read_csv(url, names=colnames)\n",
        "\n",
        "irisdata\n",
        "\n",
        "X = irisdata.drop('Class', axis=1)\n",
        "y = irisdata['Class']\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2RjgyNhFa4Uw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# First doing with a good kernel for this, the linear. But here there isn't any need for hyperparametric testing\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "svclassifier = SVC(kernel='linear',C=1.0)\n",
        "svclassifier.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = svclassifier.predict(X_test)\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(classification_report(y_test,y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEtmeHJvbqeq",
        "outputId": "48c6a4cd-a449-47cd-ee73-5c9a4d1d2a47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[13  0  0]\n",
            " [ 0 15  0]\n",
            " [ 0  0 17]]\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "    Iris-setosa       1.00      1.00      1.00        13\n",
            "Iris-versicolor       1.00      1.00      1.00        15\n",
            " Iris-virginica       1.00      1.00      1.00        17\n",
            "\n",
            "       accuracy                           1.00        45\n",
            "      macro avg       1.00      1.00      1.00        45\n",
            "   weighted avg       1.00      1.00      1.00        45\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's do hyperparametric testing"
      ],
      "metadata": {
        "id": "76mzlAtjb4oh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Second doing with a rbf kernel for this. But here we do perform the hyperparametric testing\n",
        "\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "# defining parameter range\n",
        "param_grid = {'C': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 5, 8, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 1000],\n",
        "      'gamma': [1, 0.5, 0.1, 0.05, 0.01, 0.001, 0.0001, 0.00001],\n",
        "      'kernel': ['rbf']}\n",
        "\n",
        "\n",
        "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3)\n",
        "\n",
        "\n",
        "# fitting the model for grid search\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# print best parameter after tuning\n",
        "print(grid.best_params_)\n",
        "\n",
        "\n",
        "# print how our model looks after hyper-parameter tuning\n",
        "print(grid.best_estimator_)\n",
        "\n",
        "\n",
        "grid_predictions = grid.predict(X_test)\n",
        "\n",
        "\n",
        "# print classification report\n",
        "print(confusion_matrix(y_test,grid_predictions))\n",
        "print(classification_report(y_test, grid_predictions))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dVk7TJZDb12F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now trying to find the best poly SVM kernel for our\n",
        "\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "# defining parameter range\n",
        "param_grid = {'C': [1,2,3,4,5,6,7,10,15,20,25,30,35,40,45,50],\n",
        "      'degree': [1, 2,3,4,5],\n",
        "      'kernel': ['poly']}\n",
        "\n",
        "\n",
        "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3)\n",
        "\n",
        "\n",
        "# fitting the model for grid search\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# print best parameter after tuning\n",
        "print(grid.best_params_)\n",
        "\n",
        "\n",
        "# print how our model looks after hyper-parameter tuning\n",
        "print(grid.best_estimator_)\n",
        "\n",
        "\n",
        "grid_predictions = grid.predict(X_test)\n",
        "\n",
        "\n",
        "# print classification report\n",
        "print(confusion_matrix(y_test,grid_predictions))\n",
        "print(classification_report(y_test, grid_predictions))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ct9xaaLCcOEg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
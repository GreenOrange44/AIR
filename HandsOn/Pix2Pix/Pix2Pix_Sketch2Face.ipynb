{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GreenOrange44/AIR/blob/main/HandsOn/Pix2Pix/Pix2Pix_Sketch2Face.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3X2tUCJnqqJS",
        "outputId": "33ccd4dd-a345-4be7-8490-a242889029e9"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Jul  8 05:33:25 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   50C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXeJe31sq9qN",
        "outputId": "ed968769-b647-4a18-85dd-1c4d51aaefd5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPogNsbarPBP",
        "outputId": "8310f629-5f0f-45c2-d702-437b3b5d55f6"
      },
      "source": [
        "cd '/content/gdrive/My Drive/EXP/Pix2Pix'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/EXP/Pix2Pix\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJNo7s7VrYUT",
        "outputId": "4343221d-ccd0-40b0-bc8b-8c47f5e5bd42"
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (0.18.0+cu121)\n",
            "Collecting dominate>=2.4.0 (from -r requirements.txt (line 3))\n",
            "  Downloading dominate-2.9.1-py2.py3-none-any.whl (29 kB)\n",
            "Collecting visdom>=0.1.8.8 (from -r requirements.txt (line 4))\n",
            "  Downloading visdom-0.2.4.tar.gz (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting wandb (from -r requirements.txt (line 5))\n",
            "  Downloading wandb-0.17.4-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.2.0->-r requirements.txt (line 1)) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.2.0->-r requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.2.0->-r requirements.txt (line 1)) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.2.0->-r requirements.txt (line 1)) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.2.0->-r requirements.txt (line 1)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.2.0->-r requirements.txt (line 1)) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.2.0->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.2.0->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.2.0->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.2.0->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.2.0->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.2.0->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.2.0->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.2.0->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.2.0->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.2.0->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.2.0->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.2.0->-r requirements.txt (line 1)) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.2.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.4.0->-r requirements.txt (line 2)) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.4.0->-r requirements.txt (line 2)) (9.4.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.11.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (2.31.0)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.10/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (6.3.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.16.0)\n",
            "Collecting jsonpatch (from visdom>=0.1.8.8->-r requirements.txt (line 4))\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.8.0)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 5)) (8.1.7)\n",
            "Collecting docker-pycreds>=0.4.0 (from wandb->-r requirements.txt (line 5))\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb->-r requirements.txt (line 5))\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 5)) (4.2.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 5)) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 5)) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 5)) (6.0.1)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb->-r requirements.txt (line 5))\n",
            "  Downloading sentry_sdk-2.7.1-py2.py3-none-any.whl (300 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.2/300.2 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting setproctitle (from wandb->-r requirements.txt (line 5))\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 5)) (67.7.2)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 5))\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.2.0->-r requirements.txt (line 1)) (2.1.5)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch->visdom>=0.1.8.8->-r requirements.txt (line 4))\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.2.0->-r requirements.txt (line 1)) (1.3.0)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 5))\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: visdom\n",
            "  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for visdom: filename=visdom-0.2.4-py3-none-any.whl size=1408195 sha256=23662dec0cbe7ab6ce03e37a4f37411cfb9c2854cf8bd25914bd4128a95236da\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/29/49/5bed207bac4578e4d2c0c5fc0226bfd33a7e2953ea56356855\n",
            "Successfully built visdom\n",
            "Installing collected packages: smmap, setproctitle, sentry-sdk, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, jsonpointer, dominate, docker-pycreds, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jsonpatch, gitdb, visdom, nvidia-cusolver-cu12, gitpython, wandb\n",
            "Successfully installed docker-pycreds-0.4.0 dominate-2.9.1 gitdb-4.0.11 gitpython-3.1.43 jsonpatch-1.33 jsonpointer-3.0.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 sentry-sdk-2.7.1 setproctitle-1.3.3 smmap-5.0.1 visdom-0.2.4 wandb-0.17.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXvCRRgKtqx2"
      },
      "source": [
        "#!python ./datasets/make_dataset_aligned.py --dataset-path \"./datasets/CUHK/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amFmvOMk0YAr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8532a85e-f4c2-47fe-c983-3045c52f3770"
      },
      "source": [
        "!python -m visdom.server"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking for scripts.\n",
            "Downloading scripts, this may take a little while\n",
            "It's Alive!\n",
            "INFO:root:Application Started\n",
            "INFO:root:Working directory: /root/.visdom\n",
            "You can navigate to http://4dd48e1ebb15:8097\n",
            "\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHyE5PJar8we",
        "outputId": "7a129b82-4e26-4bd4-81f5-4701afcd7a5f"
      },
      "source": [
        "!python train.py --dataroot ./datasets/CUHK --name cuhk_pix2pix --model pix2pix --direction AtoB --n_epochs 100"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------- Options ---------------\n",
            "               batch_size: 1                             \n",
            "                    beta1: 0.5                           \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "           continue_train: False                         \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ./datasets/CUHK               \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "              display_env: main                          \n",
            "             display_freq: 400                           \n",
            "               display_id: 1                             \n",
            "            display_ncols: 4                             \n",
            "             display_port: 8097                          \n",
            "           display_server: http://localhost              \n",
            "          display_winsize: 256                           \n",
            "                    epoch: latest                        \n",
            "              epoch_count: 1                             \n",
            "                 gan_mode: vanilla                       \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: True                          \t[default: None]\n",
            "                lambda_L1: 100.0                         \n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 286                           \n",
            "                       lr: 0.0002                        \n",
            "           lr_decay_iters: 50                            \n",
            "                lr_policy: linear                        \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: cycle_gan]\n",
            "                 n_epochs: 100                           \t[default: 20]\n",
            "           n_epochs_decay: 20                            \n",
            "               n_layers_D: 3                             \n",
            "                     name: cuhk_pix2pix                  \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: unet_256                      \n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                  no_html: False                         \n",
            "                     norm: batch                         \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: train                         \n",
            "                pool_size: 0                             \n",
            "               preprocess: resize_and_crop               \n",
            "               print_freq: 100                           \n",
            "             save_by_iter: False                         \n",
            "          save_epoch_freq: 5                             \n",
            "         save_latest_freq: 5000                          \n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "         update_html_freq: 1000                          \n",
            "                use_wandb: False                         \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "The number of training images = 88\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 54.414 M\n",
            "[Network D] Total number of parameters : 2.769 M\n",
            "-----------------------------------------------\n",
            "Setting up a new session...\n",
            "Exception in user code:\n",
            "------------------------------------------------------------\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\", line 203, in _new_conn\n",
            "    sock = connection.create_connection(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/util/connection.py\", line 85, in create_connection\n",
            "    raise err\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/util/connection.py\", line 73, in create_connection\n",
            "    sock.connect(sa)\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\", line 791, in urlopen\n",
            "    response = self._make_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\", line 497, in _make_request\n",
            "    conn.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\", line 395, in request\n",
            "    self.endheaders()\n",
            "  File \"/usr/lib/python3.10/http/client.py\", line 1278, in endheaders\n",
            "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
            "  File \"/usr/lib/python3.10/http/client.py\", line 1038, in _send_output\n",
            "    self.send(msg)\n",
            "  File \"/usr/lib/python3.10/http/client.py\", line 976, in send\n",
            "    self.connect()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\", line 243, in connect\n",
            "    self.sock = self._new_conn()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\", line 218, in _new_conn\n",
            "    raise NewConnectionError(\n",
            "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x79523d369f90>: Failed to establish a new connection: [Errno 111] Connection refused\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/adapters.py\", line 486, in send\n",
            "    resp = conn.urlopen(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\", line 845, in urlopen\n",
            "    retries = retries.increment(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/util/retry.py\", line 515, in increment\n",
            "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
            "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /env/main (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x79523d369f90>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/visdom/__init__.py\", line 756, in _send\n",
            "    return self._handle_post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/visdom/__init__.py\", line 720, in _handle_post\n",
            "    r = self.session.post(url, data=data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/sessions.py\", line 637, in post\n",
            "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/sessions.py\", line 589, in request\n",
            "    resp = self.send(prep, **send_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/sessions.py\", line 703, in send\n",
            "    r = adapter.send(request, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/adapters.py\", line 519, in send\n",
            "    raise ConnectionError(e, request=request)\n",
            "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /env/main (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x79523d369f90>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
            "[Errno 99] Cannot assign requested address\n",
            "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
            "[Errno 99] Cannot assign requested address\n",
            "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
            "[Errno 99] Cannot assign requested address\n",
            "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
            "Visdom python client failed to establish socket to get messages from the server. This feature is optional and can be disabled by initializing Visdom with `use_incoming_socket=False`, which will prevent waiting for this request to timeout.\n",
            "\n",
            "\n",
            "Could not connect to Visdom server. \n",
            " Trying to start a server....\n",
            "Command: /usr/bin/python3 -m visdom.server -p 8097 &>/dev/null &\n",
            "create web directory ./checkpoints/cuhk_pix2pix/web...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "End of epoch 1 / 100 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 2, iters: 12, time: 0.087, data: 2.101) G_GAN: 0.913 G_L1: 12.912 D_real: 0.478 D_fake: 0.508 \n",
            "End of epoch 2 / 100 \t Time Taken: 4 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 3, iters: 24, time: 0.084, data: 0.002) G_GAN: 1.475 G_L1: 20.824 D_real: 0.496 D_fake: 0.657 \n",
            "End of epoch 3 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 4, iters: 36, time: 0.089, data: 0.002) G_GAN: 1.859 G_L1: 12.657 D_real: 0.519 D_fake: 0.638 \n",
            "End of epoch 4 / 100 \t Time Taken: 4 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 5, iters: 48, time: 4.425, data: 0.002) G_GAN: 1.815 G_L1: 13.723 D_real: 0.631 D_fake: 0.174 \n",
            "saving the model at the end of epoch 5, iters 440\n",
            "End of epoch 5 / 100 \t Time Taken: 134 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 6, iters: 60, time: 0.088, data: 0.002) G_GAN: 2.276 G_L1: 14.618 D_real: 0.094 D_fake: 0.734 \n",
            "End of epoch 6 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 7, iters: 72, time: 0.094, data: 0.003) G_GAN: 1.794 G_L1: 14.181 D_real: 0.137 D_fake: 0.477 \n",
            "End of epoch 7 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 8, iters: 84, time: 0.094, data: 0.002) G_GAN: 1.153 G_L1: 11.947 D_real: 1.193 D_fake: 0.117 \n",
            "End of epoch 8 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "End of epoch 9 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 10, iters: 8, time: 3.058, data: 0.002) G_GAN: 1.151 G_L1: 11.769 D_real: 0.305 D_fake: 0.654 \n",
            "saving the model at the end of epoch 10, iters 880\n",
            "End of epoch 10 / 100 \t Time Taken: 64 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 11, iters: 20, time: 0.087, data: 0.001) G_GAN: 1.251 G_L1: 13.976 D_real: 0.834 D_fake: 0.235 \n",
            "End of epoch 11 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 12, iters: 32, time: 0.068, data: 0.002) G_GAN: 0.890 G_L1: 16.287 D_real: 1.112 D_fake: 0.226 \n",
            "End of epoch 12 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 13, iters: 44, time: 0.096, data: 0.003) G_GAN: 1.214 G_L1: 13.028 D_real: 0.415 D_fake: 0.328 \n",
            "End of epoch 13 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 14, iters: 56, time: 0.347, data: 0.002) G_GAN: 1.455 G_L1: 15.268 D_real: 0.117 D_fake: 0.795 \n",
            "End of epoch 14 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 15, iters: 68, time: 0.099, data: 0.003) G_GAN: 1.949 G_L1: 11.372 D_real: 1.172 D_fake: 0.119 \n",
            "saving the model at the end of epoch 15, iters 1320\n",
            "End of epoch 15 / 100 \t Time Taken: 7 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 16, iters: 80, time: 0.093, data: 0.002) G_GAN: 1.077 G_L1: 16.186 D_real: 0.300 D_fake: 0.600 \n",
            "End of epoch 16 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "End of epoch 17 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 18, iters: 4, time: 0.087, data: 0.002) G_GAN: 1.800 G_L1: 13.671 D_real: 0.213 D_fake: 0.307 \n",
            "End of epoch 18 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 19, iters: 16, time: 0.410, data: 0.003) G_GAN: 1.811 G_L1: 21.047 D_real: 0.023 D_fake: 0.945 \n",
            "End of epoch 19 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 20, iters: 28, time: 0.095, data: 0.002) G_GAN: 1.224 G_L1: 14.803 D_real: 0.612 D_fake: 0.383 \n",
            "saving the model at the end of epoch 20, iters 1760\n",
            "End of epoch 20 / 100 \t Time Taken: 8 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 21, iters: 40, time: 0.092, data: 0.002) G_GAN: 0.767 G_L1: 12.552 D_real: 1.423 D_fake: 0.131 \n",
            "End of epoch 21 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 22, iters: 52, time: 0.078, data: 0.002) G_GAN: 0.767 G_L1: 10.795 D_real: 1.196 D_fake: 0.118 \n",
            "End of epoch 22 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 23, iters: 64, time: 0.409, data: 0.003) G_GAN: 2.256 G_L1: 28.233 D_real: 0.718 D_fake: 0.165 \n",
            "End of epoch 23 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 24, iters: 76, time: 0.095, data: 0.015) G_GAN: 0.648 G_L1: 10.338 D_real: 1.641 D_fake: 0.156 \n",
            "End of epoch 24 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 25, iters: 88, time: 0.097, data: 0.002) G_GAN: 0.757 G_L1: 12.388 D_real: 0.895 D_fake: 0.446 \n",
            "saving the model at the end of epoch 25, iters 2200\n",
            "End of epoch 25 / 100 \t Time Taken: 8 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "End of epoch 26 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 27, iters: 12, time: 0.095, data: 0.272) G_GAN: 1.883 G_L1: 16.295 D_real: 0.027 D_fake: 0.626 \n",
            "End of epoch 27 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 28, iters: 24, time: 0.397, data: 0.002) G_GAN: 1.211 G_L1: 11.810 D_real: 0.758 D_fake: 0.218 \n",
            "End of epoch 28 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 29, iters: 36, time: 0.085, data: 0.012) G_GAN: 1.728 G_L1: 16.373 D_real: 0.029 D_fake: 1.216 \n",
            "End of epoch 29 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 30, iters: 48, time: 0.096, data: 0.002) G_GAN: 1.421 G_L1: 16.028 D_real: 0.594 D_fake: 0.470 \n",
            "saving the model at the end of epoch 30, iters 2640\n",
            "End of epoch 30 / 100 \t Time Taken: 8 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 31, iters: 60, time: 0.096, data: 0.002) G_GAN: 0.689 G_L1: 11.001 D_real: 0.966 D_fake: 0.364 \n",
            "End of epoch 31 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 32, iters: 72, time: 0.624, data: 0.002) G_GAN: 0.944 G_L1: 10.557 D_real: 0.652 D_fake: 0.434 \n",
            "End of epoch 32 / 100 \t Time Taken: 6 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 33, iters: 84, time: 0.097, data: 0.002) G_GAN: 1.404 G_L1: 18.951 D_real: 0.028 D_fake: 0.661 \n",
            "End of epoch 33 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "End of epoch 34 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 35, iters: 8, time: 0.094, data: 0.002) G_GAN: 1.304 G_L1: 28.325 D_real: 0.421 D_fake: 0.389 \n",
            "saving the model at the end of epoch 35, iters 3080\n",
            "End of epoch 35 / 100 \t Time Taken: 7 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 36, iters: 20, time: 0.098, data: 0.001) G_GAN: 1.706 G_L1: 15.255 D_real: 0.145 D_fake: 1.126 \n",
            "End of epoch 36 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 37, iters: 32, time: 0.352, data: 0.002) G_GAN: 1.541 G_L1: 13.402 D_real: 0.953 D_fake: 0.119 \n",
            "End of epoch 37 / 100 \t Time Taken: 6 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 38, iters: 44, time: 0.095, data: 0.002) G_GAN: 1.215 G_L1: 11.962 D_real: 0.309 D_fake: 0.458 \n",
            "End of epoch 38 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 39, iters: 56, time: 0.095, data: 0.002) G_GAN: 0.545 G_L1: 11.584 D_real: 1.295 D_fake: 0.598 \n",
            "End of epoch 39 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 40, iters: 68, time: 0.096, data: 0.002) G_GAN: 0.904 G_L1: 11.197 D_real: 0.518 D_fake: 0.408 \n",
            "saving the model at the end of epoch 40, iters 3520\n",
            "End of epoch 40 / 100 \t Time Taken: 7 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 41, iters: 80, time: 0.344, data: 0.002) G_GAN: 1.750 G_L1: 13.852 D_real: 0.445 D_fake: 0.257 \n",
            "End of epoch 41 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "End of epoch 42 / 100 \t Time Taken: 6 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 43, iters: 4, time: 0.083, data: 0.002) G_GAN: 1.323 G_L1: 16.051 D_real: 0.719 D_fake: 0.271 \n",
            "End of epoch 43 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 44, iters: 16, time: 0.104, data: 0.001) G_GAN: 1.176 G_L1: 12.751 D_real: 0.137 D_fake: 0.556 \n",
            "End of epoch 44 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 45, iters: 28, time: 0.097, data: 0.002) G_GAN: 1.660 G_L1: 13.072 D_real: 0.468 D_fake: 0.305 \n",
            "saving the model at the end of epoch 45, iters 3960\n",
            "End of epoch 45 / 100 \t Time Taken: 7 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 46, iters: 40, time: 0.372, data: 0.002) G_GAN: 1.318 G_L1: 14.991 D_real: 0.549 D_fake: 0.244 \n",
            "End of epoch 46 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 47, iters: 52, time: 0.097, data: 0.002) G_GAN: 2.014 G_L1: 10.928 D_real: 0.095 D_fake: 0.226 \n",
            "End of epoch 47 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 48, iters: 64, time: 0.095, data: 0.003) G_GAN: 2.046 G_L1: 9.716 D_real: 2.097 D_fake: 0.076 \n",
            "End of epoch 48 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 49, iters: 76, time: 0.082, data: 0.004) G_GAN: 1.793 G_L1: 16.607 D_real: 0.028 D_fake: 0.914 \n",
            "End of epoch 49 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 50, iters: 88, time: 0.384, data: 0.005) G_GAN: 1.252 G_L1: 15.057 D_real: 0.056 D_fake: 0.884 \n",
            "saving the model at the end of epoch 50, iters 4400\n",
            "End of epoch 50 / 100 \t Time Taken: 8 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "End of epoch 51 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 52, iters: 12, time: 0.096, data: 0.201) G_GAN: 1.301 G_L1: 15.135 D_real: 0.109 D_fake: 1.082 \n",
            "End of epoch 52 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 53, iters: 24, time: 0.097, data: 0.002) G_GAN: 0.663 G_L1: 10.972 D_real: 0.687 D_fake: 0.621 \n",
            "End of epoch 53 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 54, iters: 36, time: 0.078, data: 0.003) G_GAN: 0.919 G_L1: 9.774 D_real: 0.757 D_fake: 0.415 \n",
            "End of epoch 54 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 55, iters: 48, time: 0.386, data: 0.002) G_GAN: 1.337 G_L1: 16.599 D_real: 0.061 D_fake: 0.759 \n",
            "saving the model at the end of epoch 55, iters 4840\n",
            "End of epoch 55 / 100 \t Time Taken: 8 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 56, iters: 60, time: 0.090, data: 0.002) G_GAN: 1.051 G_L1: 12.281 D_real: 1.087 D_fake: 0.377 \n",
            "End of epoch 56 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 57, iters: 72, time: 0.093, data: 0.002) G_GAN: 1.532 G_L1: 11.786 D_real: 0.283 D_fake: 0.414 \n",
            "saving the latest model (epoch 57, total_iters 5000)\n",
            "End of epoch 57 / 100 \t Time Taken: 6 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 58, iters: 84, time: 0.096, data: 0.002) G_GAN: 1.082 G_L1: 12.674 D_real: 0.597 D_fake: 0.479 \n",
            "End of epoch 58 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "End of epoch 59 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 60, iters: 8, time: 0.414, data: 0.002) G_GAN: 1.877 G_L1: 12.581 D_real: 0.201 D_fake: 0.381 \n",
            "saving the model at the end of epoch 60, iters 5280\n",
            "End of epoch 60 / 100 \t Time Taken: 8 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 61, iters: 20, time: 0.096, data: 0.002) G_GAN: 1.475 G_L1: 23.336 D_real: 0.037 D_fake: 0.579 \n",
            "End of epoch 61 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 62, iters: 32, time: 0.088, data: 0.002) G_GAN: 0.863 G_L1: 14.331 D_real: 0.317 D_fake: 1.023 \n",
            "End of epoch 62 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 63, iters: 44, time: 0.097, data: 0.002) G_GAN: 1.241 G_L1: 10.342 D_real: 0.409 D_fake: 0.452 \n",
            "End of epoch 63 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 64, iters: 56, time: 0.405, data: 0.002) G_GAN: 1.308 G_L1: 16.265 D_real: 0.151 D_fake: 0.783 \n",
            "End of epoch 64 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 65, iters: 68, time: 0.092, data: 0.002) G_GAN: 0.689 G_L1: 9.750 D_real: 1.117 D_fake: 0.511 \n",
            "saving the model at the end of epoch 65, iters 5720\n",
            "End of epoch 65 / 100 \t Time Taken: 7 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 66, iters: 80, time: 0.095, data: 0.002) G_GAN: 1.045 G_L1: 11.707 D_real: 1.184 D_fake: 0.337 \n",
            "End of epoch 66 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "End of epoch 67 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 68, iters: 4, time: 0.090, data: 0.002) G_GAN: 1.277 G_L1: 12.730 D_real: 0.956 D_fake: 0.349 \n",
            "End of epoch 68 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 69, iters: 16, time: 0.614, data: 0.001) G_GAN: 1.670 G_L1: 14.290 D_real: 0.257 D_fake: 0.414 \n",
            "End of epoch 69 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 70, iters: 28, time: 0.072, data: 0.002) G_GAN: 1.592 G_L1: 12.531 D_real: 0.199 D_fake: 0.977 \n",
            "saving the model at the end of epoch 70, iters 6160\n",
            "End of epoch 70 / 100 \t Time Taken: 7 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 71, iters: 40, time: 0.097, data: 0.003) G_GAN: 1.430 G_L1: 11.749 D_real: 0.304 D_fake: 0.514 \n",
            "End of epoch 71 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 72, iters: 52, time: 0.084, data: 0.002) G_GAN: 1.402 G_L1: 10.253 D_real: 0.848 D_fake: 0.257 \n",
            "End of epoch 72 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 73, iters: 64, time: 0.467, data: 0.003) G_GAN: 0.954 G_L1: 13.174 D_real: 0.574 D_fake: 0.340 \n",
            "End of epoch 73 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 74, iters: 76, time: 0.083, data: 0.002) G_GAN: 1.136 G_L1: 10.433 D_real: 0.370 D_fake: 0.331 \n",
            "End of epoch 74 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 75, iters: 88, time: 0.098, data: 0.012) G_GAN: 0.982 G_L1: 8.419 D_real: 0.531 D_fake: 0.562 \n",
            "saving the model at the end of epoch 75, iters 6600\n",
            "End of epoch 75 / 100 \t Time Taken: 7 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "End of epoch 76 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 77, iters: 12, time: 0.094, data: 0.222) G_GAN: 2.284 G_L1: 14.036 D_real: 0.067 D_fake: 1.052 \n",
            "End of epoch 77 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 78, iters: 24, time: 0.512, data: 0.002) G_GAN: 1.020 G_L1: 10.999 D_real: 1.322 D_fake: 0.188 \n",
            "End of epoch 78 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 79, iters: 36, time: 0.080, data: 0.003) G_GAN: 1.400 G_L1: 13.164 D_real: 0.404 D_fake: 0.313 \n",
            "End of epoch 79 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 80, iters: 48, time: 0.096, data: 0.004) G_GAN: 1.574 G_L1: 13.204 D_real: 0.214 D_fake: 0.651 \n",
            "saving the model at the end of epoch 80, iters 7040\n",
            "End of epoch 80 / 100 \t Time Taken: 7 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 81, iters: 60, time: 0.087, data: 0.002) G_GAN: 1.034 G_L1: 10.096 D_real: 1.467 D_fake: 0.189 \n",
            "End of epoch 81 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 82, iters: 72, time: 0.566, data: 0.005) G_GAN: 1.530 G_L1: 14.878 D_real: 0.292 D_fake: 0.664 \n",
            "End of epoch 82 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 83, iters: 84, time: 0.091, data: 0.004) G_GAN: 0.653 G_L1: 9.148 D_real: 0.725 D_fake: 0.382 \n",
            "End of epoch 83 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "End of epoch 84 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 85, iters: 8, time: 0.097, data: 0.004) G_GAN: 2.678 G_L1: 15.636 D_real: 0.088 D_fake: 1.037 \n",
            "saving the model at the end of epoch 85, iters 7480\n",
            "End of epoch 85 / 100 \t Time Taken: 7 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 86, iters: 20, time: 0.074, data: 0.001) G_GAN: 1.457 G_L1: 12.231 D_real: 0.485 D_fake: 0.376 \n",
            "End of epoch 86 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 87, iters: 32, time: 0.526, data: 0.003) G_GAN: 1.619 G_L1: 12.972 D_real: 0.394 D_fake: 0.381 \n",
            "End of epoch 87 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 88, iters: 44, time: 0.074, data: 0.002) G_GAN: 1.056 G_L1: 10.245 D_real: 0.786 D_fake: 0.235 \n",
            "End of epoch 88 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 89, iters: 56, time: 0.094, data: 0.012) G_GAN: 1.069 G_L1: 11.314 D_real: 0.967 D_fake: 0.254 \n",
            "End of epoch 89 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 90, iters: 68, time: 0.097, data: 0.002) G_GAN: 1.514 G_L1: 16.686 D_real: 0.242 D_fake: 0.556 \n",
            "saving the model at the end of epoch 90, iters 7920\n",
            "End of epoch 90 / 100 \t Time Taken: 10 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 91, iters: 80, time: 0.506, data: 0.012) G_GAN: 1.097 G_L1: 8.722 D_real: 0.406 D_fake: 0.636 \n",
            "End of epoch 91 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "End of epoch 92 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 93, iters: 4, time: 0.092, data: 0.002) G_GAN: 1.598 G_L1: 10.684 D_real: 0.166 D_fake: 1.261 \n",
            "End of epoch 93 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 94, iters: 16, time: 0.108, data: 0.001) G_GAN: 0.327 G_L1: 9.760 D_real: 1.966 D_fake: 0.379 \n",
            "End of epoch 94 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 95, iters: 28, time: 0.084, data: 0.002) G_GAN: 1.087 G_L1: 8.960 D_real: 0.469 D_fake: 0.706 \n",
            "saving the model at the end of epoch 95, iters 8360\n",
            "End of epoch 95 / 100 \t Time Taken: 8 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 96, iters: 40, time: 0.474, data: 0.011) G_GAN: 1.815 G_L1: 14.350 D_real: 0.076 D_fake: 1.836 \n",
            "End of epoch 96 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 97, iters: 52, time: 0.098, data: 0.002) G_GAN: 1.310 G_L1: 9.300 D_real: 0.294 D_fake: 1.300 \n",
            "End of epoch 97 / 100 \t Time Taken: 6 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 98, iters: 64, time: 0.090, data: 0.003) G_GAN: 0.893 G_L1: 9.111 D_real: 0.687 D_fake: 0.508 \n",
            "End of epoch 98 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 99, iters: 76, time: 0.085, data: 0.002) G_GAN: 0.845 G_L1: 10.853 D_real: 0.739 D_fake: 0.490 \n",
            "End of epoch 99 / 100 \t Time Taken: 5 sec\n",
            "learning rate 0.0002000 -> 0.0001905\n",
            "(epoch: 100, iters: 88, time: 0.501, data: 0.012) G_GAN: 0.910 G_L1: 11.063 D_real: 0.977 D_fake: 0.417 \n",
            "saving the model at the end of epoch 100, iters 8800\n",
            "End of epoch 100 / 100 \t Time Taken: 7 sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gShA-IbBmwH",
        "outputId": "184d269e-c827-4e67-fe5c-e22ecfd148ff"
      },
      "source": [
        "!python test.py --dataroot ./datasets/CUHK --name cuhk_pix2pix --model pix2pix --direction AtoB --num_test 100"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ./datasets/CUHK               \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: latest                        \n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: cuhk_pix2pix                  \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: unet_256                      \n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                 num_test: 100                           \t[default: 50]\n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: resize_and_crop               \n",
            "              results_dir: ./results/                    \n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                use_wandb: False                         \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/cuhk_pix2pix/latest_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 54.414 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/cuhk_pix2pix/test_latest\n",
            "processing (0000)-th image... ['./datasets/CUHK/test/0000.jpg']\n",
            "processing (0005)-th image... ['./datasets/CUHK/test/0005.jpg']\n",
            "processing (0010)-th image... ['./datasets/CUHK/test/0010.jpg']\n",
            "processing (0015)-th image... ['./datasets/CUHK/test/0015.jpg']\n",
            "processing (0020)-th image... ['./datasets/CUHK/test/0020.jpg']\n",
            "processing (0025)-th image... ['./datasets/CUHK/test/0025.jpg']\n",
            "processing (0030)-th image... ['./datasets/CUHK/test/0030.jpg']\n",
            "processing (0035)-th image... ['./datasets/CUHK/test/0035.jpg']\n",
            "processing (0040)-th image... ['./datasets/CUHK/test/0040.jpg']\n",
            "processing (0045)-th image... ['./datasets/CUHK/test/0045.jpg']\n",
            "processing (0050)-th image... ['./datasets/CUHK/test/0050.jpg']\n",
            "processing (0055)-th image... ['./datasets/CUHK/test/0055.jpg']\n",
            "processing (0060)-th image... ['./datasets/CUHK/test/0060.jpg']\n",
            "processing (0065)-th image... ['./datasets/CUHK/test/0065.jpg']\n",
            "processing (0070)-th image... ['./datasets/CUHK/test/0070.jpg']\n",
            "processing (0075)-th image... ['./datasets/CUHK/test/0075.jpg']\n",
            "processing (0080)-th image... ['./datasets/CUHK/test/0080.jpg']\n",
            "processing (0085)-th image... ['./datasets/CUHK/test/0085.jpg']\n",
            "processing (0090)-th image... ['./datasets/CUHK/test/0090.jpg']\n",
            "processing (0095)-th image... ['./datasets/CUHK/test/0095.jpg']\n"
          ]
        }
      ]
    }
  ]
}